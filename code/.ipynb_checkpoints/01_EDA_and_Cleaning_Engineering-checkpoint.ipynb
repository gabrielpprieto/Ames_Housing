{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ames Housing Data and Kaggle Challenge\n",
    "> ## EDA and Data Cleaning\n",
    ">> Gabriel Perez Prieto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV, LassoCV, ElasticNet, ElasticNetCV\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot style to be used\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting max columns limit\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading train dataset into memmory\n",
    "train = pd.read_csv('../datasets/train.csv')\n",
    "test = pd.read_csv('../datasets/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the shape of the dataframe\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the first 5 rows\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the column names to lower and underscore\n",
    "train.columns = [column.lower().replace(' ','_') for column in train.columns]\n",
    "test.columns = [column.lower().replace(' ','_') for column in test.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform columns to numerical - This will fix some null values as well!\n",
    "\n",
    "qualitative_to_numeric_dict = {'pool_qc': {'Ex': 5, \n",
    "                                           'Gd': 4,\n",
    "                                           'TA': 3,\n",
    "                                           'Fa': 2,\n",
    "                                            np.nan: 0},\n",
    "                               'misc_feature': {'Elev': 5,\n",
    "                                                'Gar2': 4,\n",
    "                                                'Othr': 3,\n",
    "                                                'Shed': 2,\n",
    "                                                'TenC': 1,\n",
    "                                                 np.nan: 0},\n",
    "                               'alley': {'Grvl': 2,\n",
    "                                         'Pave': 1,\n",
    "                                          np.nan: 0},\n",
    "                               'fence': {'GdPrv': 4,\n",
    "                                         'MnPrv': 3,\n",
    "                                         'GdWo': 2,\n",
    "                                         'MnWw': 1,\n",
    "                                          np.nan: 0},\n",
    "                               'fireplace_qu': {'Ex': 5, \n",
    "                                                'Gd': 4,\n",
    "                                                'TA': 3,\n",
    "                                                'Fa': 2,\n",
    "                                                'Po': 1,\n",
    "                                                 np.nan: 0},\n",
    "                               'garage_cond': {'Ex': 5, \n",
    "                                               'Gd': 4,\n",
    "                                               'TA': 3,\n",
    "                                               'Fa': 2,\n",
    "                                               'Po': 1,\n",
    "                                                np.nan: 0},\n",
    "                               'garage_qual': {'Ex': 5, \n",
    "                                               'Gd': 4,\n",
    "                                               'TA': 3,\n",
    "                                               'Fa': 2,\n",
    "                                               'Po': 1,\n",
    "                                                np.nan: 0},\n",
    "                               'garage_finish': {'Fin': 3,\n",
    "                                                 'RFn': 2,\n",
    "                                                 'Unf': 1,\n",
    "                                                 np.nan: 0},\n",
    "                               'garage_type': {'2Types': 6,\n",
    "                                               'Attchd': 5,\n",
    "                                               'Basment': 4,\n",
    "                                               'BuiltIn': 3,\n",
    "                                               'CarPort': 2,\n",
    "                                               'Detchd': 1,\n",
    "                                                np.nan: 0},\n",
    "                               'bsmt_exposure': {'Gd': 4,\n",
    "                                                 'Av': 3,\n",
    "                                                 'Mn': 2,\n",
    "                                                 'No': 1,\n",
    "                                                  np.nan: 0},\n",
    "                               'bsmtfin_type_2': {'GLQ': 6,\n",
    "                                                  'ALQ': 5,\n",
    "                                                  'BLQ': 4,\n",
    "                                                  'Rec': 3,\n",
    "                                                  'LwQ': 2,\n",
    "                                                  'Unf': 1,\n",
    "                                                   np.nan: 0},\n",
    "                               'bsmt_cond': {'Ex': 5, \n",
    "                                             'Gd': 4,\n",
    "                                             'TA': 3,\n",
    "                                             'Fa': 2,\n",
    "                                             'Po': 1,\n",
    "                                              np.nan: 0},\n",
    "                               'bsmt_qual': {'Ex': 5, \n",
    "                                             'Gd': 4,\n",
    "                                             'TA': 3,\n",
    "                                             'Fa': 2,\n",
    "                                             'Po': 1,\n",
    "                                              np.nan: 0},\n",
    "                               'bsmtfin_type_1': {'GLQ': 6,\n",
    "                                                  'ALQ': 5,\n",
    "                                                  'BLQ': 4,\n",
    "                                                  'Rec': 3,\n",
    "                                                  'LwQ': 2,\n",
    "                                                  'Unf': 1,\n",
    "                                                   np.nan: 0},\n",
    "                               'mas_vnr_type': {'BrkCmn': 4,\n",
    "                                                'BrkFace': 3,\n",
    "                                                'CBlock': 2,\n",
    "                                                'None': 0,\n",
    "                                                 np.nan: 0,\n",
    "                                                'Stone': 1},\n",
    "                               'exter_qual': {'Ex': 5, \n",
    "                                              'Gd': 4,\n",
    "                                              'TA': 3,\n",
    "                                              'Fa': 2,\n",
    "                                              'Po': 1},\n",
    "                               'exter_cond': {'Ex': 5, \n",
    "                                              'Gd': 4,\n",
    "                                              'TA': 3,\n",
    "                                              'Fa': 2,\n",
    "                                              'Po': 1},\n",
    "                               'heating_qc': {'Ex': 5, \n",
    "                                              'Gd': 4,\n",
    "                                              'TA': 3,\n",
    "                                              'Fa': 2,\n",
    "                                              'Po': 1},\n",
    "                               'central_air': {'Y': 1, \n",
    "                                               'N': 0},\n",
    "                               'kitchen_qual': {'Ex': 5, \n",
    "                                                'Gd': 4,\n",
    "                                                'TA': 3,\n",
    "                                                'Fa': 2,\n",
    "                                                'Po': 1},\n",
    "                               'electrical': {'SBrkr': 4,\n",
    "                                              'FuseA': 3,\n",
    "                                              'FuseF': 2,\n",
    "                                              'FuseP': 1,\n",
    "                                              'Mix': 0}\n",
    "                              }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace qualitative values by a range of integers\n",
    "train.replace(qualitative_to_numeric_dict, inplace=True)\n",
    "test.replace(qualitative_to_numeric_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for null columns again as see what is left\n",
    "train.isnull().mean()[train.isnull().mean() > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().mean()[test.isnull().mean() > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of columns with null values\n",
    "null_train = [column for column in train.columns if train[column].isnull().sum() > 0]\n",
    "null_test = [column for column in test.columns if test[column].isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try Imputation Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values(dataframe, null_columns):\n",
    "    for column in null_columns:\n",
    "        dataframe[column + '_was_missing'] = dataframe[column].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values(train, null_train)\n",
    "missing_values(test, null_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define numerical and nominal columns\n",
    "numerical_variables = train.select_dtypes(include='number').columns\n",
    "nominal_variables = train.select_dtypes(exclude='number').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Imputation\n",
    "# # train data\n",
    "# imputer = SimpleImputer(strategy='median')\n",
    "# train_numerical = pd.DataFrame(imputer.fit_transform(train[numerical_variables]),\n",
    "#                                columns=train[numerical_variables].columns)\n",
    "# train_nominal = train[nominal_variables]\n",
    "\n",
    "# train = pd.concat([train_numerical, train_nominal], axis=1)\n",
    "\n",
    "# # test data\n",
    "# test_numerical = pd.DataFrame(imputer.transform(test[numerical_variables]),\n",
    "#                                columns=test[numerical_variables].columns)\n",
    "# test_nominal = test[nominal_variables]\n",
    "\n",
    "# test = pd.concat([test_numerical, test_nominal], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function\n",
    "for column in null_train:\n",
    "    train[column].fillna(train[column].median(), inplace=True)\n",
    "    \n",
    "for column in null_test:\n",
    "    test[column].fillna(test[column].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for duplicated values\n",
    "print(train.duplicated().sum())\n",
    "print(test.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA ( Exploratory Data Analysis )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting distribution of sale price\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.hist(train['saleprice'], bins=10)\n",
    "plt.title('Distribution of House Price', size=18, pad=10)\n",
    "plt.xlabel('Sale Price', size=12)\n",
    "plt.ylabel('Frequency', size=12)\n",
    "plt.axvline(train['saleprice'].mean(), color='red')\n",
    "plt.axvline(train['saleprice'].median(), color='black');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting distribution of log of sale price - Normalize\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.hist(np.log(train['saleprice']), bins=10)\n",
    "plt.title('Distribution of Log House Price', size=18, pad=10)\n",
    "plt.xlabel('Sale Price', size=12)\n",
    "plt.ylabel('Frequency', size=12)\n",
    "plt.axvline(np.log(train['saleprice']).mean(), color='red')\n",
    "plt.axvline(np.log(train['saleprice']).median(), color='black');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to integers nominal variables that were transformed into numerical\n",
    "for var in nominal_variables.values:\n",
    "    try:\n",
    "        train[var] = train[var].astype(int)\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "# redefine numerical and nominal columns\n",
    "numerical_variables = train.select_dtypes(include='number')\n",
    "nominal_variables = train.select_dtypes(exclude='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlations with target variable ['saleprice']\n",
    "correlations_saleprice = train.corr()[['saleprice']].abs().sort_values(['saleprice'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list with column names for columns with correlation > .5 with ['saleprice']\n",
    "strong_correlations = correlations_saleprice.loc[correlations_saleprice['saleprice'] >= .5][1:].index.values\n",
    "strong_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a heatmap for the most relevant correlations with saleprice\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(correlations_saleprice.loc[correlations_saleprice['saleprice'] >= .5][1:],\n",
    "            annot=True, annot_kws={\"size\": 13}, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.yticks(size=13)\n",
    "plt.xticks(size=13)\n",
    "plt.title('Heatmap - Most Relevant Correlations with Sale Price', size=16, pad=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatterplots of  Numerical Variables - Strong Correlation with Saleprice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# creating scatterplots for numerical variables with ['saleprice']\n",
    "nrows=int(np.ceil((len(strong_correlations))/2))\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=2, figsize= (13, 2.5 * len(strong_correlations)))\n",
    "\n",
    "plt.tight_layout(pad=4)\n",
    "ax = ax.ravel() \n",
    "for index, column in enumerate(strong_correlations):\n",
    "    sns.scatterplot(x = train[column], y = train['saleprice'], ax=ax[index]) \n",
    "    ax[index].set_title(strong_correlations[index], size=14)\n",
    "    ax[index].set_xlabel(strong_correlations[index], size=13)\n",
    "    ax[index].set_ylabel('saleprice', size=13);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chcecking Outliers - From Scatterplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['gr_liv_area'] > 5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['garage_cars'] == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['total_bsmt_sf'] > 5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['1st_flr_sf'] > 3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['garage_yr_blt'] > 2200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['mas_vnr_area'] > 1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping outliers\n",
    "rows_to_drop = [960, 1885, 925, 328, 616, 1699, 1409]\n",
    "for row in rows_to_drop:\n",
    "    train.drop(row, inplace=True)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms for Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting histograms for every numerical column - checking distributions\n",
    "train.hist(figsize=(13,14));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Amongst Strong Correlated Variables ( With SalePrice ) - Look for Possible Interaction Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting heatmap to look for possible interaction terms\n",
    "\n",
    "# create a figure\n",
    "plt.figure(figsize=(13,10))\n",
    "\n",
    "# correlations data\n",
    "corr = train[strong_correlations].corr()\n",
    "\n",
    "# Set up mask so triangle at the top is white\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set title\n",
    "plt.title('Correlations Heatmap - Strong Correlation Variables',fontsize=18)\n",
    "\n",
    "# create heatmap\n",
    "sns.heatmap(corr, mask=mask, square=True, annot=True, cmap='coolwarm', vmin=-1, vmax=1);\n",
    "\n",
    "# Adapted from https://seaborn.pydata.org/generated/seaborn.heatmap.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Interaction Terms For Other Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ##### Criteria: Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputting 0 for columns that do not exist on test set\n",
    "missing_cols = []\n",
    "for column in train.columns:\n",
    "    if column not in test.columns and column != 'saleprice':\n",
    "        missing_cols.append(column)\n",
    "        test[column] = 0\n",
    "\n",
    "print(missing_cols)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing for polynomial features for numerical variables\n",
    "poly_features = train[numerical_variables.columns].drop('saleprice', axis=1)\n",
    "poly_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate PolynomialFeatures\n",
    "poly = PolynomialFeatures(include_bias=False)\n",
    "poly_train = poly.fit_transform(train[poly_features.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_test = poly.transform(test[poly_features.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view X_poly in a DataFrame\n",
    "poly_train = pd.DataFrame(poly_train, columns=poly.get_feature_names(numerical_variables.columns))\n",
    "poly_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view poly_test in a DataFrame\n",
    "poly_test = pd.DataFrame(poly_test, columns=poly.get_feature_names(numerical_variables.columns))\n",
    "poly_test.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ##### Criteria: Create a total sq_ft for the house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating df['total_area']\n",
    "poly_train['total_area'] = poly_train['total_bsmt_sf'] + poly_train['1st_flr_sf'] + poly_train['2nd_flr_sf'] \\\n",
    "                   + poly_train['gr_liv_area'] + poly_train['garage_area']\n",
    "\n",
    "poly_test['total_area'] = poly_test['total_bsmt_sf'] + poly_test['1st_flr_sf'] + poly_test['2nd_flr_sf'] \\\n",
    "                   + poly_test['gr_liv_area'] + poly_test['garage_area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplots for Nominal Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to create boxplot for nominal variables\n",
    "def subplot_boxplots(dataframe, list_of_columns):\n",
    "      \n",
    "    nrows = int(np.ceil(len(list_of_columns)/2)) # Makes sure you have enough rows\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=nrows,\n",
    "                           ncols=2,\n",
    "                           figsize=(13, 5 * nrows))\n",
    "    plt.tight_layout(pad=4)\n",
    "    ax = ax.ravel() \n",
    "    \n",
    "    for index, column in enumerate(list_of_columns):\n",
    "        \n",
    "        sns.boxplot(x=dataframe[column], y=dataframe['saleprice'] ,ax=ax[index])\n",
    "        ax[index].set_title(list_of_columns[index], size=14)\n",
    "        ax[index].set_xlabel(list_of_columns[index], size=13)\n",
    "        ax[index].set_ylabel('saleprice', size=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plotting boxplots to look for nominal variables to be 'dummied'\n",
    "subplot_boxplots(train, nominal_variables.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dummy Variables ( Qualitative )\n",
    "> #### Variables with High Variation on Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of the variables to be dummied - chosen by analyzing boxplots\n",
    "dummies_list = ['ms_zoning', 'condition_1', 'condition_2',\n",
    "                'neighborhood', 'exterior_1st', 'exterior_2nd', 'sale_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in dummies_list:\n",
    "    if item not in poly_train:\n",
    "        poly_train[item] = train[item]\n",
    "for item in dummies_list:\n",
    "    if item not in poly_test:\n",
    "        poly_test[item] = train[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating function to generate dummies for selected variables\n",
    "def create_dummies(dataframe, dummies_list):\n",
    "    dataframe = pd.get_dummies(dataframe, columns=dummies_list, drop_first=True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dummies to dataframe\n",
    "poly_train = create_dummies(poly_train, dummies_list)\n",
    "poly_test = create_dummies(poly_test, dummies_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_variables = poly_train.select_dtypes(include='number').columns\n",
    "nominal_variables = poly_train.select_dtypes(exclude='number').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = poly_train.reset_index(drop=True)\n",
    "X = sm.add_constant(X)\n",
    "y = train['saleprice'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = sm.OLS(y, X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = list(model.pvalues[model.pvalues > 0.05].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = poly_train[selected_columns]\n",
    "y = train['saleprice']\n",
    "\n",
    "# Model Prep: Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.25, shuffle=True)\n",
    "\n",
    "# transforming y to y_log - normalizing distribution\n",
    "y_train_log = y_train.map(np.log)\n",
    "y_test_log = y_test.map(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null model\n",
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA - Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class on how to implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV - Linear Regression and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to run Pipeline + GridSearchCV\n",
    "def run_model_gs(pipeline, parameters, cv=5):\n",
    "    \n",
    "    # Instantiate RandomizedSearchCV\n",
    "    gs = GridSearchCV(pipeline,\n",
    "                      parameters,\n",
    "                      cv=cv,\n",
    "                      verbose=1,\n",
    "                      n_jobs=-1)\n",
    "       \n",
    "    # Fit GridSearch to training data\n",
    "    gs.fit(pd.DataFrame(X_train, columns=X.columns), pd.Series(y_train_log, name='saleprice'))\n",
    "    \n",
    "           \n",
    "    # Best mean score out of cross validation out of all models tested (cvec)\n",
    "    print(f'Best Score: {gs.best_score_}')\n",
    "    \n",
    "    # Best Paramenters\n",
    "    print(f'Best Parameters: {gs.best_params_}')\n",
    "    \n",
    "    # Save best model as gs_cvec_logreg_model\n",
    "    gs_model = gs.best_estimator_\n",
    "    \n",
    "    # Score model on training set.\n",
    "    print(f'Training Accuracy Score: {round(gs_model.score(X_train, y_train_log),4)}')\n",
    "\n",
    "    # Score model on testing set.\n",
    "    print(f'Testing Accuracy Score: {round(gs_model.score(X_test, y_test_log),4)}')\n",
    "    \n",
    "    # Predictions\n",
    "    preds = gs_model.predict(X_test)\n",
    "    \n",
    "    print(f'RMSE: {round(np.sqrt(mean_squared_error(y_test_log, preds)),4)}')\n",
    "    print(f'RMSLE: {round(np.sqrt(mean_squared_log_error(y_test_log, preds)),4)}')\n",
    "\n",
    "    return gs_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_ridge = Pipeline(steps=[('scaler', MinMaxScaler()),\n",
    "                                 ('lr', Ridge())])\n",
    "\n",
    "params_ridge = {\n",
    "    'lr__alpha': [x for x in range(1,21)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = run_model_gs(pipeline_ridge, params_ridge, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lasso = Pipeline(steps=[('scaler', MinMaxScaler()),\n",
    "                                 ('lr', Lasso())])\n",
    "\n",
    "params_lasso = {\n",
    "    'lr__alpha': [0.0001,0.0009,0.001,0.002,0.003,0.01,0.1,1,10,100],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = run_model_gs(pipeline_lasso, params_lasso, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_enet = Pipeline(steps=[('scaler', MinMaxScaler()),\n",
    "                              ('enet', ElasticNet())])\n",
    "\n",
    "params_enet = {\n",
    "    'enet__alpha': [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007],\n",
    "    'enet__l1_ratio': [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet = run_model_gs(pipeline_enet, params_enet, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_xgb = Pipeline(steps=[('scaler', MinMaxScaler()),\n",
    "                              ('xgb', XGBRegressor())])\n",
    "\n",
    "params_xgb = {\n",
    "    'xgb__max_depth': [4],\n",
    "    'xgb__learning_rate': [0.1],\n",
    "    'xgb__n_estimators': [200],\n",
    "    'xgb__colsample_bytree': [1],\n",
    "    'xgb__alpha': [0.1],\n",
    "    'xgb__min_child_weight': [1],\n",
    "    'xgb__gamma': [0],\n",
    "    'xgb__subsample': [1],\n",
    "    'xgb__colsample_bytree': [1]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = run_model_gs(pipeline_xgb, params_xgb, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lgbm = Pipeline(steps=[('scaler', MinMaxScaler()),\n",
    "                              ('lgbm', LGBMRegressor())])\n",
    "\n",
    "params_lgbm = {\n",
    "#     'lr__alpha': [0.0001,0.0009,0.001,0.002,0.003,0.01,0.1,1,10,100],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = run_model_gs(pipeline_lgbm, params_lgbm, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voting Regressor - Ensembing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote = VotingRegressor([('Ridge', ridge), ('Lasso', lasso),\n",
    "                        ('ElasticNet', enet), ('XGBRegressor', xgb),\n",
    "                        ('LGBMRegressor', lgbm)],\n",
    "                        n_jobs=-1)\n",
    "\n",
    "vote = vote.fit(X_train, y_train_log)\n",
    "\n",
    "# Best mean score out of cross validation out of all models tested (cvec)\n",
    "# print(f'Best Score: {vote.best_score_}')\n",
    "\n",
    "# Score model on training set.\n",
    "print(f'Training Accuracy Score: {vote.score(X_train, y_train_log)}')\n",
    "\n",
    "# Score model on testing set.\n",
    "print(f'Testing Accuracy Score: {vote.score(X_test, y_test_log)}')\n",
    "\n",
    "# Predictions\n",
    "preds = vote.predict(X_test)\n",
    "\n",
    "print(f'RMSE: {np.sqrt(mean_squared_error(y_test_log, preds))}')\n",
    "print(f'RMSLE: {np.sqrt(mean_squared_log_error(y_test_log, preds))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training classifiers\n",
    "ridge.fit(X_train, y_train_log)\n",
    "lasso.fit(X_train, y_train_log)\n",
    "enet.fit(X_train, y_train_log)\n",
    "xgb.fit(X_train, y_train_log)\n",
    "lgbm.fit(X_train, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/ensemble/plot_voting_regressor.html \\\n",
    "#sphx-glr-auto-examples-ensemble-plot-voting-regressor-py\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(ridge.predict(X_test[:30]), 'gd', label='Ridge', ms=8)\n",
    "plt.plot(lasso.predict(X_test[:30]), 'b^', label='Lasso', ms=8)\n",
    "plt.plot(enet.predict(X_test[:30]), 'ys', label='ElasticNet', ms=8)\n",
    "plt.plot(xgb.predict(X_test[:30]), 'k^', label='XGBoostRegressor', ms=8)\n",
    "plt.plot(lgbm.predict(X_test[:30]), 'gd', label='LGBMRegressor', ms=8)\n",
    "plt.plot(vote.predict(X_test[:30]), 'r*', label='VotingRegressor', ms=15)\n",
    "\n",
    "plt.tick_params(axis='x', which='both', bottom=False, top=False,\n",
    "                labelbottom=False)\n",
    "plt.ylabel('Predicted', size=14)\n",
    "plt.xlabel('Testing Samples', size=14)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title('Comparison of Individual Predictions with Ensemble', size=18, pad=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = vote.predict(X_test)\n",
    "residuals =  preds - y_test_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(X_test['saleprice'], pd.DataFrame(preds, columns='preds'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting residuals histogram\n",
    "plt.figure(figsize=(14,6))\n",
    "residuals.hist()\n",
    "plt.title('Residuals Histogram', size=18)\n",
    "plt.ylabel('Frequency', size=14)\n",
    "plt.axvline(0, color='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting scatter for predictions and residuals\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.scatter(preds, residuals)\n",
    "plt.axhline(color='r')\n",
    "plt.title('Residuals of Predictions', size=18)\n",
    "plt.xlabel('Predictions', size=14)\n",
    "plt.ylabel('Residuals', size=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaggle Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputting 0 for columns that do not exist on test set\n",
    "missing_cols = []\n",
    "for column in poly_train.columns:\n",
    "    if column not in poly_test.columns and column != 'saleprice':\n",
    "        missing_cols.append(column)\n",
    "        poly_test[column] = 0\n",
    "\n",
    "print(missing_cols)\n",
    "print(f' Train Shape: {poly_train.shape}')\n",
    "print(f' Test Shape: {poly_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_test['preds'] = np.exp(vote.predict(poly_test[selected_columns]))\n",
    "poly_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = poly_test[['id', 'preds']].copy()\n",
    "submission.rename({'id':'Id', 'preds': 'SalePrice'}, inplace=True)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving clean dataframe\n",
    "submission.to_csv('./submission.csv', index_label=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
